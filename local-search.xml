<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>搜广推学习之路（三）</title>
    <link href="/Post3/"/>
    <url>/Post3/</url>
    
    <content type="html"><![CDATA[<h2 id="推荐系统课程">推荐系统课程</h2><p>王树森推荐系统课程</p><h3 id="概要">概要</h3><h4 id="基本概念">基本概念</h4><p>下图为小红书中推荐系统的转化流程 <img src="/img/转化流程.png" alt="推荐系统转化流程" /></p><p>下图为一些消费指标，这些指标可以反映用户对于推荐是否满意。</p><ul><li>点击率=点击次数/曝光次数</li><li>点赞率=点赞次数/点击次数</li><li>收藏率=收藏次数/点击次数</li><li>转发率=转发次数/点击次数</li><li>阅读完成率=滑动到底次数/点击次数 x f(笔记长度)</li></ul><p>对于阅读完成率来说，存在一个潜在问题：短笔记天然更容易获得高完成率，而长笔记即使质量很高，完成率也可能较低。所以我们就使用一个归一化函数<span class="math inline"><em>f</em>( ⋅ )</span>将笔记长度归一化，乘该归一化长度可以一定程度上消除笔记长度带来的偏差。</p><p>上述消费指标都是一些短期指标，这些指标有意义，但并不是衡量推荐系统好坏的根本指标，这是因为如果只关注短期消费指标，那么给用户推荐的内容就会呈现同质化严重的现象，会导致用户迅速审美疲劳，从而降低用户粘性。所以短期消费指标不是最终的指标，最重要的指标是北极星指标：</p><ul><li>用户规模：日活用户数(DAU)、月活用户数(MAU)</li><li>消费：人均使用推荐的时长、人均阅读笔记的数量</li><li>发布：发布渗透率、人均发布量</li></ul><p>用户今天使用了小红书，那么就给小红书提供了一个DAU；用户这个月使用了小红书，不论是登陆了一天还是30天，都给小红书提供了一个MAU。用户规模与推荐系统的好坏是强相关的，推荐系统越好，用户规模越大。</p><p>下图为推荐系统的实验流程： <img src="/img/实验流程.png" alt="实验流程" /></p><p>先使用离线实验可以大致反映算法的好坏，但离线实验没有线上实验可靠，之前的北极星指标都是指线上指标，线上实验我们首先进行小流量AB测试，将用户随机分为实验组和对照组，实验组用新策略，对照组用旧策略，对照两组指标，判断实验组是否会优于旧策略，如果实验组显著优于旧策略就可以加大流量最终推全。</p><h4 id="推荐系统链路">推荐系统链路</h4><p>推荐系统目标：从几亿物品中选取几十个物品推荐给用户。</p><p>通过下图链路，实现该筛选过程： <img src="/img/推荐系统的链路.png" alt="推荐系统的链路" /></p><p>首先是召回，我们通过召回从数据库中取出一些笔记，在实践中通常有许多条召回通道，而召回通道包括有协同过滤、双塔模型、关注的作者等等。在小红书中，有几十条召回通道，每条召回通道取回几十到几百篇笔记，这些召回通道一共返回几千篇笔记，然后推荐系统会融合这些笔记，并进行去重和过滤的操作（这里过滤是指去掉用户不喜欢的作者、不喜欢的笔记）。</p><p>在召回之后，下一步是排序。通常将排序分为粗排和精排，粗排使用比较简单的模型快速对几千篇笔记进行打分，保留分数最高的几百篇笔记，精排是使用一个较大的神经网络对几百篇笔记打分。精排相对粗排使用的模型更大、特征更多，相对应的计算也会更复杂。结果会更准确。所以为了平衡计算量和准确度我们先粗排后再进行精排。</p><p>如下图所示，粗排和精排都是在神经网络中输入用户特征、物品特征和统计特征信息，然后经过神经网络训练，输出预测的点击率、点赞率、收藏率和转发率，再将这些指标进行融合就可以得到排序分数，这也是我们进行筛选和排序的依据。 <img src="/img/排序.png" alt="推荐系统的排序" /></p><p>在排序后，每篇笔记都有一个分数，表示用户对笔记的兴趣有多高。然后还需要再从几百篇笔记中进行随机抽样，抽取几十篇笔记然后利用规则将内容相似的笔记进行打散，并插入广告和运营物品，根据生态再调整排序。其中多样性抽样（如MMR、DPP）是最重要的。</p><h4 id="ab测试">A/B测试</h4><p>A/B测试就相当于是使用一小份样本来做预实验，以此来判断改进的真实效果，同时用于确定网络参数的最优取值。</p><p><strong>随机分桶</strong>：做A/B测试，需要对用户进行随机分桶，具体操作如下图所示： <img src="/img/随机分桶.png" alt="随机分桶" /> <img src="/img/随机分桶2.png" alt="随机分桶" /></p><p><strong>分层实验</strong>：分层目标解决“流量不够用”的问题。在一个公司中会有许多团队和部门，都需要做A/B测试，比如推荐系统（召回、粗排、精排、重排）团队、用户界面团队和广告团队。每个团队都需要做实验，那么可能需要同时做成千上百个实验，但将用户随机分为10组，1组作为对照组，那么最多同时只能做9个实验，显然这无法达到需求。所以我们就需要做分层实验。下面具体介绍分层实验。</p><p>首先将实验分为很多层，比如召回、用户界面等等，同层之间实验是互斥的，都是召回实验，A策略占据了1号桶，那么其他策略就不可以再使用1号桶了。而不同层之间的实验是正交的。（用户同时参与不同层的实验，我们也能通过统计方法分离出每个实验的独立效果） <img src="/img/分层实验.png" alt="分层实验" /></p><p>如下例所示，假设系统有n个用户，召回层将用户分为了m个桶，均匀打散后，粗排层也可将用户分为m个桶。当我们评估粗排层的实验效果时，对于粗排层的实验组和对照组来说，它们包含召回组各个桶用户的比例都是相同的，在这种情况下，我们可以认为粗排组实验组相较于对照组的变化是由于粗排组自身策略的不同造成的。 <img src="/img/分层实验2.png" alt="分层实验" /></p><p>当然也不是所有实验都可以正交：</p><ol type="1"><li>同类的策略（比如召回层的不同通道）天然互斥，对于同一用户只能使用其中一种；</li><li>同类的策略可能相互抵消或相互增强，互斥可以避免同类策略相互干扰；</li><li>不同类的策略（比如添加召回通道和优化粗排模型）会通常不会相互干扰，才可以做正交的两层。</li></ol><h4 id="holdout机制">Holdout机制</h4><p>Holdout机制解决的是长期效果评估的问题，比如说一家公司不停进行召回、粗排、精排和重排等实验，一段时间后，如果管理层询问这些所有层的优化累积起来，核心业务指标提升了多少，如果没有Holdout，我们无法评估这个问题，因为每个用户在A层为对照组，在B层也可能是对照组，所以所有用户都或多或少被实验影响，我们没有“未受干扰”的基准进行比较。所以Holdout机制就是提供这个基准。 <img src="/img/Holdout.png" alt="Holdout" /></p><p>Holdout机制的基本思想如下：</p><ol type="1"><li>取10%的用户作为Holdout桶，推荐系统使用剩余90%的用户做实验，两者互斥；</li><li>考察10%Holdout桶与90%实验桶的差异（需归一化）作为整个部门的业务指标收益；</li><li>每个考核周期结束之后，清除Holdout桶，让推全实验从90%用户扩大到100%用户；</li><li>重新随机划分用户，得到Holdout桶和实验桶，开始下一轮考核周期；</li><li>初始的新Holdout桶与实验桶的各种业务指标的差异接近0，随着召回、粗排、精排、重排实验上线和推全，差异会逐渐扩大。</li></ol><h4 id="实验推全和反转实验">实验推全和反转实验</h4><p><strong>实验推全</strong>：在Holdou机制基础上，观测到某个策略对某个桶有明显提升，关闭A/B测试，将策略推全到整个90%用户上。需要在召回层之前新建一个推全层，该层与其他层正交。 <img src="/img/实验推全.png" alt="实验推全" /></p><p>但实验推全还存在一个问题，有些指标（点击、交互）可以立刻收到薪策略的影响，短期内给出反馈。但有一些指标（留存）具有滞后性，短期内是无法给出反馈的，需要长期观测。但一方面我们希望早日推全新策略，以空出桶来供其他实验进行，但另一方面我们也不希望忽略这些滞后性的指标。那么我们就引入了反转实验。</p><p><strong>反转实验</strong>：在实验推全的新层中设立一个旧策略的桶，长期观测实验指标。且holdout桶与反转桶也无关。在考核周期结束后，清除holdout桶，推全策略时，反转桶仍然不变保持旧策略，只有在反转实验结束后才会关闭反转桶，真正将新策略推全至100%的用户。 <img src="/img/反转实验.png" alt="反转实验" /></p><h3 id="召回-retrieval">召回 (Retrieval)</h3><h4 id="基于物品的协同过滤-itemcf">基于物品的协同过滤 (ItemCF)</h4><p>ItemCF的核心思想：用户的兴趣具有一定的连贯性，喜欢某个物品的用户往往也会对相似的物品感兴趣。比如用户A喜欢<span class="math inline"><em>i</em><em>t</em><em>e</em><em>m</em><sub>1</sub></span>，而<span class="math inline"><em>i</em><em>t</em><em>e</em><em>m</em><sub>2</sub></span>与<span class="math inline"><em>i</em><em>t</em><em>e</em><em>m</em><sub>1</sub></span>相似，那么很大可能用户A也喜欢<span class="math inline"><em>i</em><em>t</em><em>e</em><em>m</em><sub>2</sub></span>。</p><p>那么我们如何判断两个物品是相似的？可以用过重叠用户来判断，比如喜欢<span class="math inline"><em>i</em><em>t</em><em>e</em><em>m</em><sub>1</sub></span>的用户中70%的用户还同时<span class="math inline"><em>i</em><em>t</em><em>e</em><em>m</em><sub>2</sub></span>，那么我们认为<span class="math inline"><em>i</em><em>t</em><em>e</em><em>m</em><sub>2</sub></span>与<span class="math inline"><em>i</em><em>t</em><em>e</em><em>m</em><sub>2</sub></span>相似。当然这只是一个通俗的解释，下面介绍具体算法。</p><ol type="1"><li>量化用户对于交互过的物品的兴趣，给出兴趣分数<span class="math inline"><em>l</em><em>i</em><em>k</em><em>e</em>(<em>u</em><em>s</em><em>e</em><em>r</em>, <em>i</em><em>t</em><em>e</em><em>m</em><sub><em>j</em></sub>)</span>（这一步是根据用户的交互行为进行打分的，比如点赞、收藏等行为）；</li><li>计算新物品与交互过的物品的相似度<span class="math inline"><em>s</em><em>i</em><em>m</em>(<em>i</em><em>t</em><em>e</em><em>m</em><sub><em>j</em></sub>, <em>i</em><em>t</em><em>e</em><em>m</em>)</span>；</li><li>预估用户对于候选物品的兴趣 <span class="math inline">∑<em>l</em><em>i</em><em>k</em><em>e</em>(<em>u</em><em>s</em><em>e</em><em>r</em>, <em>i</em><em>t</em><em>e</em><em>m</em><sub><em>j</em></sub>) × <em>s</em><em>i</em><em>m</em>(<em>i</em><em>t</em><em>e</em><em>m</em><sub><em>j</em></sub>, <em>i</em><em>t</em><em>e</em><em>m</em>)</span>。</li></ol><figure><img src="/img/ItemCF.png" alt="ItemCF" /><figcaption aria-hidden="true">ItemCF</figcaption></figure><p><strong>物品的相似度</strong>：基本思路是两个物品的受众重合度越高，那么两个物品的相似度也越高。所以初步定义物品相似度为公式(1)，但该公式过于简单没有考虑用户对物品的喜欢程度，所以我们对该公式进一步优化得到公式(2)。其实我们将喜欢程度简化为0和1时，公式(2)也就是公式(1)了。 <img src="/img/物品相似度.png" alt="物品相似度" /></p><p>公式(2)其实就是常见的余弦相似度表达式，我们将<span class="math inline"><em>W</em><sub>1</sub></span>集合每个元素对<span class="math inline"><em>i</em><sub>1</sub></span>的喜欢程度看作一个向量，<span class="math inline"><em>W</em><sub>2</sub></span>集合每个元素对<span class="math inline"><em>i</em><sub>2</sub></span>的喜欢程度看作一个向量。分子非同时喜欢两个物品的用户，相乘为0直接忽略，即为公式中V集合的用户对两个物品的喜欢程度相乘。 <img src="/img/QianJianTec1764826154957.jpg" alt="物品相似度" /></p><p>下面介绍ItemCF召回的完整流程</p><ol type="1"><li>事先做<strong>离线</strong>计算<ol type="1"><li>建立“用户-&gt;物品”的索引<ul><li>记录用户最近点击交互过的物品，并计算兴趣分数，根据索引可以得到用户近期感兴趣的列表</li><li>{用户，（物品ID，兴趣分数）}</li></ul></li><li>建立“物品-&gt;物品”的索引<ul><li>计算物品之间的两两相似度，对于每个物品，可以根据索引找到它最相似的k个物品</li><li>{物品，（物品ID，相似度）}</li></ul></li></ol></li><li><strong>线上</strong>做召回<ol type="1"><li>给定用户ID，通过“用户-&gt;物品”索引，找到用户近期感兴趣的物品列表 (last-n)</li><li>对于 last-n 列表中的每个物品，通过“物品-&gt;物品”的索引，找到 top-k 相似物品</li><li>对于取回的相似物品 （最多有 nk 个），用公式预估用户对物品的兴趣分数</li><li>返回分数最高的 100 个物品，作为推荐结果</li></ol></li></ol><p><img src="/img/离线计算.png" alt="离线计算" /> <img src="/img/线上召回.png" alt="线上召回" /></p><p>线上召回时索引可以避免暴力枚举所有物品。虽然离线计算量大，但是有效减少了线上计算量。</p><h4 id="swing召回通道">Swing召回通道</h4><p>Swing召回通道是ItemCF的变体，二者的区别在于定义物品的相似度。</p><p>对于ItemCF算法，在计算两个物品相似度时，我们认为两个物品的受众重合度越高，那么这两个物品的相似度就越高。但这就存在一个问题，如图所示，“护肤品打折”和“字节裁员”，这两个毫不相关的话题，受众重合度应该很低。但如果这两个帖子被分享到同一个微信群聊，那么这个群聊中的用户都会同时与这两个帖子产生交互。按照ItemCF算法，会错误地认为这两个是相似的物品，与事实相悖。针对这个问题，就产生了Swing召回算法。 <img src="/img/Snipaste_2025-12-04_22-23-57.png" alt="ItemCF相似度的不足" /></p><p>Swing的直觉来源是，如果大量用户同时喜欢两个物品，且这些用户之间的相关性低，那么这两个物品一定是强关联。所以如下图公式所示，两个用户的重合度越高，那么这两个用户在计算两个物品相似度中的贡献就越小。这样就有效避免了上述问题。注意分母中的<span class="math inline"><em>α</em></span>是一个调节因子，防止分母为0。 <img src="/img/Swing1.png" alt="Swing" /> <img src="/img/Swing2.png" alt="Swing" /></p><h4 id="基于用户的协同过滤-usercf">基于用户的协同过滤 (UserCF)</h4><p>UserCF与ItemCF也类似，ItemCF是通过相似物品来推荐，而UserCF是通过相似用户来推荐。UserCF的核心是：如果user1和user2相似，那么user2喜欢的物品A，我们认为user1很大可能也喜欢。</p><p>同ItemCF，在UserCF中，也可以通过相似的用户和这些用户对于物品A的兴趣分数，得到user对一个新物品的兴趣分数。 <img src="/img/Snipaste_2025-12-05_16-08-19.png" /></p><p>在UserCF中，我们需要求解的就是两个用户之间的用户相似度。两个用户喜欢的物品重合度越高，我们认为这两个用户的相似度越高，所以产生了公式1。但这个公式具有一个问题就是没有考虑热门物品的影响，比如哈利波特，这个IP太过于经典，即使用户A和B是相差很大的两个用户，他们也可能同时喜欢哈利波特。所以我们要降低热门物品的权重，改进得到公式2。 <img src="/img/用户相似度.png" alt="用户相似度" /></p><p>下面介绍UserCF召回的完整流程</p><ol type="1"><li>事先做<strong>离线</strong>计算<ol type="1"><li>建立“用户-&gt;物品”的索引<ul><li>记录用户最近点击交互过的物品，并计算兴趣分数，根据索引可以得到用户近期感兴趣的列表</li><li>{用户，（物品ID，兴趣分数）}</li></ul></li><li>建立“用户-&gt;用户”的索引<ul><li>计算用之间的两两相似度，对于每个用户，可以根据索引找到他最相似的k个用户</li><li>{用户，（用户ID，相似度）}</li></ul></li></ol></li><li><strong>线上</strong>做召回<ol type="1"><li>给定用户ID，通过“用户-&gt;用户”的索引，找到 top-k 相似物品 2.对于 top-k 列表中的每个用户，通过“用户-&gt;物品”索引，找到用户近期感兴趣的物品列表 (last-n)</li><li>对于取回的 nk 个 相似物品，用公式预估用户对每个物品的兴趣分数</li><li>返回分数最高的 100 个物品，作为召回结果</li></ol></li></ol><figure><img src="/img/UserCF.png" alt="UserCF" /><figcaption aria-hidden="true">UserCF</figcaption></figure><h4 id="离散特征处理">离散特征处理</h4><p>把序号转化为向量，one-hot不介绍了，因为在数据样本很多的情况下，使用one-hot编码是不现实的，我们下面简单介绍Embedding（嵌入）的方法。</p><p>在Embedding中，参数以矩阵的形式保存，矩阵的大小是向量为度x类别数量。 <img src="/img/Embedding.png" alt="Embedding" /></p><p>如果训练的好，是可以通过embedding看出物品的特点，如下图所示，位于第一象限的物品都为动画片，位于第二象限的物品为漫威影片。 <img src="/img/Embedding2.png" alt="Embedding" /></p><p>Embedding是业界常用的一种方式。TensorFlow、PyTorch等提供Embedding层，所以更详细的就不再介绍。</p><h4 id="矩阵补充">矩阵补充</h4><p>（这种方法已不再使用） 如图是基于Embedding做推荐的模型，即为矩阵补充模型。输入为用户ID和物品ID，输出为用户对物品的兴趣分数。 <img src="/img/矩阵补充.png" alt="矩阵补充模型" /></p><p>训练模型参数，首先需要考虑数据集的问题，矩阵补充模型中的数据集如下： <img src="/img/矩阵补充数据集.png" alt="矩阵补充模型数据集" /></p><p>然后通过Embedding层，将用户ID和物品ID映射为向量，第u号用户映射为<span class="math inline"><em>a</em><sub><em>u</em></sub></span>，第i号物品映射为<span class="math inline"><em>b</em><sub><em>i</em></sub></span>，由于<span class="math inline"> &lt; <em>a</em><sub><em>u</em></sub>, <em>b</em><sub><em>i</em></sub>&gt;</span>是第u号用户对第i号物品的兴趣分数预估值，所以我们训练模型的优化目标就是令该预估值尽量接近兴趣分数真实值y，所以得到优化目标公式。 <img src="/img/矩阵补充2.png" alt="矩阵补充模型" /></p><figure><img src="/img/矩阵补充4.png" alt="矩阵补充模型" /><figcaption aria-hidden="true">矩阵补充模型</figcaption></figure><p>如下图所示，绿色部分即为我们数据集中所包含的部分，我们通过绿色部分对模型进行训练，然后再使用训练好的模型对灰色部分进行预测，从而将该矩阵补充完整，然后就可以根据兴趣分数的大小对用户进行推荐。 <img src="/img/矩阵补充3.png" alt="矩阵补充模型" /></p><p>但该模型在实践中效果并不好，原因如下图所示： <img src="/img/矩阵补充5.png" alt="矩阵补充模型" /></p><h4 id="线上服务">线上服务</h4><p>矩阵补充模型训练好后可作为召回通道，所以我们需要将模型存储好。在矩阵补充模型中需要存储的为矩阵A和B。用户矩阵A存储到key-value表中，key是用户ID，value为A的一列，给定用户ID，返回向量（用户的embedding）。物品矩阵B的存储比较复杂，不是简单的key-value存储。</p><p>将embedding向量存储好之后，可以进行线上服务。用户使用小红书时，小红书后台会做召回，将用户ID作为key，查询key-value表，得到该用户对应的向量，记作a。然后查找用户最有可能感兴趣的k个物品（最近邻查找），但不可能枚举所有物品，一一计算用户对该物品的兴趣分数（<span class="math inline"> &lt; <em>a</em>, <em>b</em><sub><em>i</em></sub>&gt;</span>）。所以我们需要加速最近邻查找，避免枚举。</p><p>下面给出一个例子： 近似最近邻查找的例子 1. 物品ID通过embedding得到物品向量，如下图所示，将其向量分布区域划分为n个小区域（余弦划分为扇形区域）， 每个区域使用一个单位向量表示； 2. 以该区域的表示向量作为key，区域中所有物品的列表value，n个区域就有n个索引； 3. 在线上快速做推荐，分别计算用户向量与所有索引向量的相度； 4. 找到相似度最高的索引，再分别计算用户向量与该索引区域包含的所有物品向量的相似度； 5. 选取最相似的k个点，作为召回结果。</p><figure><img src="/img/近似最近邻查找.png" alt="近似最近邻查找" /><figcaption aria-hidden="true">近似最近邻查找</figcaption></figure><p>在工业界中，Milvus、Faiss、HnswLib等向量数据库都支持近似最近邻查找。</p><h4 id="双塔模型">双塔模型</h4><p>在矩阵补全模型的基础上，双塔模型不是简单考虑了用户和物品的ID，还包括用户和物品的特征，如离散特征（用户所在城市）和连续特征（用户的年龄）。在计算用户对物品的兴趣分数时使用余弦相似度取代内积。 <img src="/img/双塔模型.png" alt="双塔模型" /> <img src="/img/双塔模型2.png" alt="双塔模型" /></p><p>需要注意上图，适用于召回的双塔模型是先分别通过神经网络生成表征，再计算两个表征之间的相似度（兴趣分数），称为<strong>后期融合</strong>。而在精排和粗排中，则需要使用<strong>前期融合</strong>，如下图所示，也就是先融合物品和用户的特征向量，再通过神经网络输出兴趣分数。 <img src="/img/Snipaste_2025-12-07_22-35-42.png" /></p><p>接下来介绍双塔模型的训练方式，双塔模型有三种训练方式：</p><ul><li>Pointise: 独立看待每个正样本、负样本，做简单的二元分类；</li><li>Pairwise: 每次取一个正样本、负样本组成二元组；</li><li>Listwise: 每次取一个正样本、多个负样本组成一个list，训练方式类似于多元分类。</li></ul><p>正样本指的是用户感兴趣的物品，即用户点击过的物品，而负样本指的就是用户不感兴趣的物品。了解这个之后，接下来我们具体介绍这三种训练方式。</p><blockquote><p>Pointwise训练：</p><ol type="1"><li>把召回看作二元分类任务</li><li>鼓励用户与正样本的余弦相似度 cos(a, b) 接近 +1</li><li>鼓励用户与负样本的余弦相似度 cos(a, b) 接近 -1</li><li>控制正负样本的数量为 1:2 或者 1:3 （经验值）</li></ol></blockquote><blockquote><p>Pairwise训练：</p><p>如下图所示，pairwise同时取一个正样本和一个负样本，得到用户对这组正样本的余弦相似度 <span class="math inline"><em>c</em><em>o</em><em>s</em>(<em>a</em>, <em>b</em><sup>+</sup>)</span>、负样本的余弦相似度 <span class="math inline"><em>c</em><em>o</em><em>s</em>(<em>a</em>, <em>b</em><sup>−</sup>)</span>。由于我们同时拥有一个正、负样本，所以我们可以将训练目标设置为<span class="math inline"><em>c</em><em>o</em><em>s</em>(<em>a</em>, <em>b</em><sup>+</sup>) &gt; <em>c</em><em>o</em><em>s</em>(<em>a</em>, <em>b</em><sup>−</sup>)</span>，我们要设置一个边界m，令<span class="math inline"><em>c</em><em>o</em><em>s</em>(<em>a</em>, <em>b</em><sup>+</sup>)</span>和<span class="math inline"><em>c</em><em>o</em><em>s</em>(<em>a</em>, <em>b</em><sup>−</sup>)</span>之间的差值至少大于等于m。因此我们也可以得到Pairwise的损失函数，训练时以最小化损失函数为训练目标。 <img src="/img/pairwise.png" alt="Pairwise训练" /> <img src="/img/pairwise2.png" alt="Pairwise训练" /></p></blockquote><blockquote><p>Listwise训练：</p><p>Listwise方法是将用户对正负样本的余弦相似度通过softmax函数转化为0-1范围内的数值，然后正样本的标签为1，负样本的标签为0.然后最小化交叉熵损失函数。 <img src="/img/listwise.png" alt="Listwise训练" /></p></blockquote><p>综上所述，三种训练方法本质都是要将用户与正样本的余弦相似度接近1，用户与负样本的余弦相似度接近0。只是输入的正负样本数量不同。</p><p>在上述过程。我们还存在一个遗留问题，正样本是指用户感兴趣的物品、负样本是用户不敢兴趣的物品。那我们要怎么选择正负样本？</p><p>这个样本选择较为简单，我们选择曝光且有点击的“用户-物品”二元组作为正样本即可。但由于28法则，少部分热门物品会占据大量的点击，这就会导致我们得到的正样本多是热门物品样本，使得那些用户感兴趣但冷门的物品被遗漏。从而造成热门物品更热、冷门物品更冷。</p><p>对此我们采用的解决方案是过采样冷门物品，或者降采样热门物品。过采样是指一个样本出现多次，也就是增加冷门物品被采样的概率。降采样是指抛弃一些样本，也就是抛弃一些热门物品，抛弃概率与热门物品的点击次数正相关。我们通过这样的方法手动降低数据偏见对模型训练造成的影响，从而更加多元化地为用户推荐物品。</p><p>选择负样本即为选择用户不感兴趣的样本，也可以理解为是在推荐系统链路每一步中被淘汰的物品。但要注意，在召回过程淘汰的物品大概率是用户不感兴趣的物品，这部分被称为<strong>简单负样本</strong>；在排序过程被淘汰的物品是用户具有一定兴趣，但不是最感兴趣的样本，这部分被称为<strong>困难负样本</strong>；而最终曝光但未被点击的样本并不可以作为负样本。因为这些已经是筛选出来的用户感兴趣的物品，没被点击到是其他因素的影响。</p><blockquote><p>简单负样本也可以分为全体物品和batch内负样本。</p><p>首先介绍从全体物品中抽取简单负样本。</p><p>因为在几亿个物品中只有几千个物品被召回，所以我们可以近似认为全体物品就是未被召回的物品。我们只需要在全体物品中进行抽样作为负样本。</p><p>但是抽样时我们如果采用均匀抽样，由于少部分物品为热门物品，大部分都为冷门物品，会导致负样本中大部分都为冷门物品，这也是不公平的，同样会导致热门物品更热、冷门物品更冷。</p><p>所以我们需要采用的时非均匀抽样抽样，负样本抽样概率与物品的热门程度正相关。抽样概率正比于点击次数的0.75次方，这里的0.75是经验值。</p><p>接下来介绍batch内负样本。</p><p>如下图所示，在这样一个用户点击物品的batch内，用户与其点击的物品作为正样本，那么用户大概率对于其他物品是不感兴趣的，我们将其作为负样本。这样一个batch内会有n(n-1)个负样本。但也会出现一个问题，一个物品出现在batch内的概率与其点击次数成正比，那么也就意味着物品在batch内成为负样本的概率与其点击次数成正比。这与我们希望的点击次数的0.75次方是不一致的。这种情况下会导致对热门物品的打击过大，造成偏差，因此我们要采取措施进行纠偏，防止过分打压热门物品，如下图所示。采取该措施可以保证人们物品的cos不会过小。该措施只需要在训练时加入，线上召回时无需调整。</p><p><img src="/img/batch内负样本2.png" alt="batch内负样本" /> <img src="/img/batch内负样本.png" alt="batch内负样本" /> <img src="/img/batch内负样本3.png" alt="batch内负样本" /></p></blockquote><blockquote><p>困难负样本是被排序淘汰的样本，分为被粗排淘汰的物品（比较困难）和精排中分数靠后的物品（非常困难）。因为这两者都是用户对其有一定兴趣但不是最感兴趣的，如果不够精确，很容易被划分为正样本，所以对他们进行分类是困难的。</p></blockquote><p>在实际训练中，我们常常使用混合负样本，比如50%为简单负样本，50%为困难负样本。</p><p>接下来介绍双塔模型的<strong>线上召回和更新</strong>。</p><p>在训练好双塔模型的两个塔后，我们先使用物品塔提取物品特征，离线存储物品向量。对于几亿个物品，用物品塔计算每个物品的特征向量b，把&lt;物品向量，物品ID&gt;存入向量数据库，以便加速最近邻查找。</p><p>然后进行线上召回，查找用户最感兴趣的k个物品。首先根据给定的用户ID和画像，使用用户塔线上计算用户向量a，然后把a作为query，调用向量数据库做最近邻查找，返回余弦相似度最大的k个物品，作为召回结果。</p><p>由于用户的兴趣变化是动态变化的，所以我们选择线上实时计算用户向量。而物品的特征相对稳定，且物品的数量过于庞大，所以我们选择线上召回之前，离线存储物品向量。</p><p>在实践中，需要对模型不断进行更新。更新也分为“全量更新”和“增量更新”。</p><p>全量更新较为简单，每天凌晨（一天结束时），在原先模型参数的基础上，使用最新一天的数据训练1epoch，得到新的用户塔神经向量和物品向量，供线上召回使用。全量更新对数据流、系统的要求较低。</p><p>而增量更新相对复杂一些。因为增量更新是实时进行更新，以确保能够与用户的兴趣完全契合，比如用户早上刷小红书产生了新的兴趣点，那么小红书就要通过增量更新实时更新，让用户在中午或者更早时候就可以刷到与新的兴趣点相关的内容。增量更新需要实时收集线上数据，做流式处理，生成TFRecord文件，对模型做online learning，增量更新用户ID Embedding参数，注意不对神经网络其它部分（全连接层）的参数进行更新。然后发布用户ID Embedding，供用户塔线上计算用户向量。</p><p>当然在事件中，我们将全量更新和增量更新结合起来，如下图所示。 <img src="/img/更新.png" /></p><h4 id="双塔模型自监督学习">双塔模型+自监督学习</h4><p>在完全了解双塔模型后，我们将双塔模型和自监督学习结合起来，可以提升业务指标。自监督学习是为了将物品塔训练的更好，以得到更具代表性、更通用、更健壮的物品特征。</p><p><img src="/img/Snipaste_2025-12-21_22-21-37.png" /></p><p>自监督学习的基本思想如下，我们使用不同的特征表示方法对物品进行表示，同一物品经不同变化得到的特征向量仍有高相似度，而不同物品之间的特征向量具有低相似度。 <img src="/img/Snipaste_2025-12-21_22-59-27.png" /> <img src="/img/Snipaste_2025-12-21_22-59-46.png" /></p><p>下面为常见的四种特征变换方法： <img src="/img/RandonMask.png" alt="RandomMask" /> <img src="/img/Dropout.png" alt="Dropout" /> <img src="/img/互补特征.png" alt="互补特征" /> <img src="/img/Mask关联特征.png" alt="互补特征" /> <img src="/img/Mask关联特征2.png" alt="互补特征" /></p><p>下面为自监督学习的训练流程： <img src="/img/自监督学习.png" alt="自监督学习" /> <img src="/img/自监督学习2.png" alt="自监督学习" /> <img src="/img/自监督学习3.png" alt="自监督学习" /></p><p>下面将自监督学习和双塔模型结合起来。 <img src="/img/双塔模型+自监督学习.png" /></p><h4 id="其他召回通道">其他召回通道</h4><ol type="1"><li>地理位置召回：GeoHash召回、同城召回<ul><li>地理位置召回是基于用户可能对附近发生的事情感兴趣，且该种召回与个性化无关，只是根据地理位置推荐当前位置的优质笔记。GeoHash 和同城的区别在于，GeoHash 是根据经纬度编码表示地图上一个长方形区域，索引为GeoHash -&gt; 优质笔记列表（按时间倒排）；同城召回是根据所在和曾在的城市，索引为城市 -&gt; 优质笔记列表。</li></ul></li><li>作者召回：关注的作者召回、有交互的作者召回、相似的作者召回<ul><li>关注的作者召回：用户对关注的作者发布的笔记感兴趣。索引：用户 -&gt; 关注的作者，作者 -&gt; 发布的笔记。召回：用户 -&gt; 关注的作者 -&gt; 最新发布的笔记。</li><li>有交互的作者召回：用户对某篇笔记感兴趣，那么也可能对该作者的其他笔记感兴趣。索引：用户 -&gt; 有交互的作者。召回：用户 -&gt; 有交互的作者 -&gt; 最新发布的笔记。注意在索引时会及时更新最近有交互的作者，长时间未交互的作者删去。</li><li>相似的作者召回：类似于ItemCF，用户喜欢一个作者那么大概率也对与其相似的作者感兴趣。索引：作者 -&gt; 相似作者。召回：用户 -&gt; 感兴趣的作者 -&gt; 相似的作者 -&gt; 最新发布的笔记。</li></ul></li><li>缓存召回<ul><li>复用前几次推荐精排的结果。精排的结果已经是用户最感兴趣的了，但在送入重排后做多样性抽样，只有几十篇笔记会被挑选出来，剩下的大部分笔记没有被曝光，被浪费了。所以我们直接将这些位于精排前50但没有曝光的笔记缓存起来，作为一条召回通道。在用户下次刷新小红书时将缓存通道中的笔记取出来作为一路召回的结果。但显然缓存大小是固定的，所以需要退场机制，下面为常见的退场规则：一旦笔记成功曝光，就从缓存退场；如果超过缓存大小，就移除最先进入缓存的笔记；笔记最多被召回若干次，达到这个次数就退场；每篇笔记最多保存若干天，达到这个天数就退场；想让低曝光笔记缓存更长时间，基于曝光次数设置退场规则。</li></ul></li></ol><h4 id="曝光过滤-bloom-filter">曝光过滤 &amp; Bloom Filter</h4><p>曝光过滤是指如果用户看过某个物品的话，我们就不再将该物品曝光给该用户。所以我们记录曝光给每个用户的物品（只需要记录一个月以内的，因为小红书只召回一个月内发布的笔记），对于每个召回的物品，判断它是否已经曝光给该用户，将曝光过的物品排除掉。 但在判断找回物品是否曝光时，如果暴力对比时间复杂度很大，所以采用Bloom Filter。</p><p>Bloom Filter 判断一个物品ID是否在已曝光的物品集合中，如果结果为no，那么该物品一定不在集合中，如果结果为yes，那么该物品<strong>可能</strong>在集合中。</p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>搜广推学习之路（二）</title>
    <link href="/Post2/"/>
    <url>/Post2/</url>
    
    <content type="html"><![CDATA[<h2 id="深度学习">深度学习</h2><h3 id="循环神经网络rnn">循环神经网络（RNN）</h3><p>普通前馈神经网络（如CNN）一般处理的是固定长度、互不相关的输入，比如一张图片、一个固定长度的特征向量。但很多任务中，当前时刻的输出跟“之前发生了什么”强相关，例如：机器翻译：当前要翻译的词要看前面一句话的意思；语言模型：预测下一个词要看前面所有词；股票预测：今天的走势与过去几天的价格、成交量有关。因此，为了能够更好的处理序列的信息，RNN产生了。</p><p>首先介绍一下RNN的基础结构，如下图所示： <img src="/img/RNN结构.png" alt="RNN结构" /></p><p>在解析这张图之前，我们先将W即其所在圆圈忽略，那么就是一个全连接神经网络的简略图，展开即下图所示： <img src="/img/神经网络.png" alt="对应的全连接神经网络" /></p><p>X是神经网络的输入向量，U是输入层到隐藏层的参数矩阵，S是隐藏层的输出向量，V是隐藏层到输出层的参数矩阵，O是输出层的向量，即为神经网络的输出向量。</p><p>那么RNN中的W是什么？这个W参数就是RNN实现“记忆”的关键。我们将RNN结构图展开如下图所示： <img src="/img/RNN展开图.png" alt="RNN展开图" /></p><ul><li><span class="math inline"><em>x</em><sub><em>t</em></sub></span>表示网络每一时刻的输入</li><li><span class="math inline"><em>o</em><sub><em>t</em></sub></span>表示网络每一时刻的输出</li><li><span class="math inline"><em>s</em><sub><em>t</em></sub></span>表示网络的隐藏层的状态输出</li><li>U、V、W是RNN在所有时刻的共享参数</li></ul><p>根据该展开图，我们可以得到RNN的计算公式： <img src="/img/RNN计算公式.png" alt="RNN计算公式" /></p><p>其中<span class="math inline"><em>g</em>( ⋅ )</span>和<span class="math inline"><em>f</em>( ⋅ )</span>函数均为激活函数。我们若将状态<span class="math inline"><em>s</em><sub><em>t</em></sub></span>不断使用公式进行展开就可以得到： <img src="/img/Snipaste_2025-11-23_22-58-11.png" /></p><p>从上面可以看出，循环神经网络的输出值，是受前面历次输入值<span class="math inline"><em>x</em><sub><em>t</em></sub>、<em>x</em><sub><em>t</em> − 1</sub>、<em>x</em><sub><em>t</em> − 3</sub>、...</span>影响的，这就是为什么循环神经网络可以“记忆历史”。</p><p>为了方便与LSTM进行对比，在这里给出RNN的一个新的结构图，这里的<span class="math inline"><em>h</em><sub><em>t</em></sub></span>即为我们上述提到的<span class="math inline"><em>s</em><sub><em>t</em></sub></span>，隐藏层状态。 <img src="/img/RNN.png" alt="RNN" /></p><h3 id="lstm">LSTM</h3><p>对于普通RNN来说，当序列很长时，RNN很难将早期步骤的信息传递到后期步骤。比如，在句子“这只猫因为吃了太多的奶酪，所以现在……很饱”中，RNN可能早就忘记了主语是“猫”，导致后面预测错误。它更擅长记忆“短期”信息，而遗忘“长期”信息。而针对该问题，LSTM被提出。</p><p>LSTM主要由<strong>细胞状态</strong>和<strong>门控机制</strong>组成，而门控机制又由<strong>遗忘门、输入门和输出门</strong>组成。 <img src="/img/LSTM.png" alt="LSTM" /></p><p>LSTM首先会决定从细胞状态中丢弃哪些信息。通过<span class="math inline"><em>x</em></span>和<span class="math inline"><em>h</em><sub><em>t</em></sub></span>的操作，并经过sigmoid函数，得到0,1的向量，0代表清除记忆，1代表保留记忆. <img src="/img/遗忘门.png" alt="遗忘门" /></p><p>下一步决定将哪些新信息存储在细胞状态中。这分为两部分，首先，一个sigmoid层决定要更新哪些值。接下来，tanh层创建一个新的候选值向量，代表可能会加入到状态中的新内容。将把这两者结合起来，以更新状态。 <img src="/img/输入门.png" alt="输入门" /></p><p>得到需要遗忘和新增的记忆后，我们就可以更新细胞状态。将旧状态与遗忘向量相乘，忘掉我们决定忘记的东西。然后加上新的候选值。 <img src="/img/更新细胞状态.png" alt="更新细胞状态" /></p><p>最后我们决定输出什么，这个输出也是新的隐藏层状态<span class="math inline"><em>h</em><sub><em>t</em></sub></span>。首先，我们运行一个sigmoid层，它决定输出细胞状态的哪些部分。然后，我们将细胞状态输入到tanh层（为了将值压在−1​和1之间）并将其乘以sigmoid门的输出，这样我们就只输出我们决定要输出的部分。 <img src="/img/输出门.png" alt="输出门" /></p><h3 id="自注意力机制">自注意力机制</h3><p>自注意力（Self-Attention）机制是一种特殊的注意力机制，对于序列中的每一个元素（比如一个词），它会计算序列中所有其他元素对该元素的“重要性”或“相关度”，从而帮助模型更好地理解序列中的上下文信息，更准确地处理序列数据。</p><blockquote><p>比如在处理“这只动物没有穿过街道，因为它太累了。”这个句子时，模型通过计算句子中所有其他词与 “它” 的相关性，可以判断 “动物” 与 “它” 的联系最紧密，所以得到“它”指的是“动物”而不是“街道”。</p></blockquote><p>为了实现上述思想，自注意力机制引入了三个重要的向量：<strong>查询（query）、键（key）和值（value）</strong>。</p><p>接下来具体阐述自注意力机制的过程，下图所示公式即为自注意力机制的核心： <img src="/img/自注意力机制.png" alt="自注意力机制" /></p><p>自注意力机制公示的本质可以看作是<span class="math inline"><em>s</em><em>o</em><em>f</em><em>t</em><em>m</em><em>a</em><em>x</em>(<em>X</em><em>X</em><sup><em>T</em></sup>)<em>X</em></span>，下面给出一个具体的例子，来探究该公式的具体意义。</p><p>首先是<span class="math inline"><em>X</em><em>X</em><sup><em>T</em></sup></span>，根据定义，两个向量的点积是两个向量的长度与它们夹角余弦的积。如果两向量夹角为90°，那么结果为0，代表两个向量线性无关。如果两个向量夹角越小，两向量在方向上相关性也越强，结果也越大。点积反映了两个向量在方向上的相关性，结果越大越相关。然后使用一个Softmax函数，对其归一化，可以凸显相关性最大的值并抑制远低于最大值的其他分量。最后使用<span class="math inline"><em>s</em><em>o</em><em>f</em><em>t</em><em>m</em><em>a</em><em>x</em>(<em>X</em><em>X</em><sup><em>T</em></sup>)</span>点乘X，就可以将得到的相关性信息也包含到X向量中。</p><p>注意下图中的数字是我随便编的，只起到一个帮助理解的作用，不对具体意义负责。 <img src="/img/自注意力机制解释.png" /></p><p>对自注意力机制的本质了解后，自注意力机制本身的公式也很好理解了，将X与矩阵<span class="math inline"><em>W</em><sub><em>q</em></sub>、<em>W</em><sub><em>k</em></sub>、<em>W</em><sub><em>v</em></sub></span>相乘，得到<span class="math inline"><em>Q</em>、<em>K</em>、<em>V</em></span>向量后执行相同的操作。（矩阵<span class="math inline"><em>W</em><sub><em>q</em></sub>、<em>W</em><sub><em>k</em></sub>、<em>W</em><sub><em>v</em></sub></span>是训练得到的）</p><p>那么问题来了，我们为什么不能直接使用X，而要再引入Q、K、V？自注意力机制为了让每个 token 既能“提问”、又能“被识别”、还要“贡献内容”，必须把输入 X 映射成 3 个角色：Q、K、V。三个线性变换让模型在不同子空间中学习匹配模式和信息提取，极大增强了表达能力。同时线性变换引入了额外的可学习参数<span class="math inline"><em>W</em><sub><em>q</em></sub>、<em>W</em><sub><em>k</em></sub>、<em>W</em><sub><em>v</em></sub></span>。这增加了模型的容量，使其能够拟合更复杂的数据分布和语言现象。</p><blockquote><p>“提问”：这是query的角色。序列中的每个token都通过Q向量发出一个query：在这个上下文中，哪些token的信息对我最重要？</p><p>“被识别”：这是key的角色。每个token都通过K向量提供一个“身份标识”，用于回应其他token的查询，告诉别人“我是谁，我有什么特征”。</p><p>“贡献内容”：这是value的角色。每个token都通过V向量来提供它最终要贡献的“实质信息内容”。这个信息可能需要是经过提炼的，与原始输入不同。</p></blockquote><p>除了上述问题，在注意力机制中还除以了根号<span class="math inline"><em>d</em><sub><em>k</em></sub></span>，是为了防止点积 <span class="math inline"><em>Q</em><em>K</em><sup><em>T</em></sup></span> 随维度增大而数值过大，使 Softmax 的梯度过小，从而导致训练不稳定。本质是对点积进行标准化，使其在 Softmax 中保持适当的数值范围，避免梯度消失，稳定训练。下图给出一个具体的例子： <img src="/img/根号dk.png" /></p><p>至此，自注意力机制就解释清楚了，我们最后给出自注意力机制的完整图解。 <img src="/img/自注意力机制流程.png" alt="自注意力机制图解" /></p><p>多头注意力机制是将多个自注意力机制组合形成的，在transformer中使用了8个多头注意力机制，所以我们这里也以8个自注意力机制为例。多头注意力机制首先使用8个w矩阵生成Q、K、V，执行8次自注意力机制得到8个Z矩阵，然后将8个Z矩阵拼接起来（Concat），然后乘附加权重矩阵<span class="math inline"><em>W</em><sub><em>o</em></sub></span>得到最终的Z。 <img src="/img/多头注意力机制.png" alt="多头注意力机制" /> <img src="/img/多头注意力机制2.png" alt="多头注意力机制" /></p><h3 id="transformer">Transformer</h3><figure><img src="/img/transformer.png" alt="Transformer" /><figcaption aria-hidden="true">Transformer</figcaption></figure><p>transformer的结构可分为encoder和decoder两大部分，其中encoder部分有6个encoder块，decoder部分也有6个decoder块。encoder部分最后一个encoder块的信息会传递给每一个decoder块使用。 <img src="/img/trm总体架构.png" alt="Transformer" /></p><p>在介绍具体架构前，我们先介绍输入部分，由于transformer是并行处理数据的，所以transformer并不像RNN一样，可以包含时间顺序，为了解决这一问题，transformer在输入部分添加了位置编码 Positional Encoding。下图为位置编码公式： <img src="/img/位置编码.png" alt="位置编码" /></p><p>为了理解上述表达式，我们以<span class="math inline"><em>d</em><sub><em>m</em><em>o</em><em>d</em><em>e</em><em>l</em></sub> = 4</span>的短语“I am a robot”为例，展示该短语的位置编码矩阵，为了方便计算，我们使用100代替公式中的10000。需要说明的是i的计算，短语维度为4，2i表示偶数维度，2i+1表示奇数维度，所以对于四个维度0、1、2、3，对应的i为0、0、1、1。 <img src="/img/PE例子.png" alt="PE例子" /></p><p>有了位置编码后，我们将输入向量x与其对应的位置编码相加就可以得到transformer的输入。 <img src="/img/Snipaste_2025-11-28_20-21-56.png" /></p><p>然后我们介绍encoder部分，该部分由 Multi-Head Attention, Add &amp; Normalize, Feed Forward, Add &amp; Normalize 组成的。 <img src="/img/encoder.png" alt="encoder" /></p><p>Add &amp; Normalize层包括Add和Normalize两部分，这里的Add是残差连接，即y = x + F(x)。在encoder中即为X + SelfAttention(X)和X + FeedForward(X)。 <img src="/img/残差连接.png" alt="残差连接" /></p><p>残差连接之后，将结果normalize，normalize 指 Layer Normalization，通常用于 RNN 结构，Layer Normalization 会将每一层神经元的输入都转成均值方差都一样的，这样可以加快收敛。</p><p>Feed Forward就是一个两层的神经网络，先线性变换，然后ReLU非线性，再线性变换。</p><p>encoder部分就结束了，接下来我们介绍decoder部分。 首先是decoder部分的输入，在训练阶段，我们采用teacher forcing策略，假设我们的训练数据为“I love you”，而经翻译得到的目标序列为“我爱你”，那么我们将目标序列加上特殊符号，<span class="math inline"> &lt; <em>B</em><em>e</em><em>g</em><em>i</em><em>n</em>&gt;</span>表示序列开始，<span class="math inline"> &lt; <em>e</em><em>n</em><em>d</em>&gt;</span>表示序列结束，这样完整的目标序列就为“<span class="math inline"> &lt; <em>B</em><em>e</em><em>g</em><em>i</em><em>n</em>&gt;</span>我爱你<span class="math inline"> &lt; <em>e</em><em>n</em><em>d</em>&gt;</span>”，而decoder的输入需要将完整的目标序列右移一位，并去掉结尾的<span class="math inline"> &lt; <em>e</em><em>n</em><em>d</em>&gt;</span>，所以decoder的输入就为“<span class="math inline"> &lt; <em>B</em><em>e</em><em>g</em><em>i</em><em>n</em>&gt;</span>我爱你”。</p><p>decoder部分与encoder部分不同的有两个地方，decoder部分包含有两个 Multi-Head Attention 层，其中第一个 Multi-Head Attention 层采用了 Masked 操作；第二个 Multi-Head Attention 层的K,V矩阵使用 Encoder 的编码信息矩阵（最终输出）进行计算，而Q使用 Decoder 第一个自注意力输出计算，所以第二个注意力机制也被叫做Cross-Attention 交叉注意力。</p><p>接下来我们具体介绍 Masked Multi-Head Attention层。如果没有 Mask，在训练时，Decoder 在计算第一个词 <span class="math inline"> &lt; <em>B</em><em>e</em><em>g</em><em>i</em><em>n</em>&gt;</span> 的表示时，就能“看到”整个答案序列（如“我爱你”）。这被称为信息泄露。模型会学会简单地复制输入中的下一个词，而不是真正学习如何基于上文进行预测。所以为了确保生成目标，我们在注意力机制中引入一个掩码（Mask），来屏蔽掉未来的信息。下图为具体的过程，之后的softmax、与V相乘等过程与一般的多头注意力机制一致，所以没有给出。 <img src="/img/Masked%20Multi-Head%20Attention.png" alt="Masked Multi-Head Attention" /></p><p>而交叉注意力机制很简单，只要将encoder最后一层的K和V矩阵用于每一层的decoder即可，其余部分与一般的多头注意力机制没有区别。 <img src="/img/Cross%20Attention.png" /></p><p>至此，transformer就介绍完了。</p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>搜广推学习之路（一）</title>
    <link href="/Post1/"/>
    <url>/Post1/</url>
    
    <content type="html"><![CDATA[<!-- 添加音乐名片 https://github.com/metowolf/MetingJS --><!-- require APlayer --><!-- <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.css"><script src="https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.js"></script> --><!-- require MetingJS --><!-- <script src="https://cdn.jsdelivr.net/npm/meting@2/dist/Meting.min.js"></script><meting-js    server="netease"    type="song"    id="2707655756"></meting-js> --><p>研0，尝试零基础转搜广推，在此记录我的学习过程，夯实基础的同时为后来者提供经验。</p><!-- 这是我在网上找到的[参考路线](https://www.xiaohongshu.com/explore/687339c9000000001203212f?xsec_token=CBW_s-Z8Fc-se6uDqatKGzEqwLxXtV08CZ3k1WsmtQnRk=&xsec_source=app_share)。 --><h2 id="机器学习">机器学习</h2><p>快速：基础概念、树和集成学习等（尤其是逻辑回归、bagging、boosting部分） 长期：吴恩达机器学习</p><h3 id="绪论">绪论</h3><h4 id="基本术语">基本术语</h4><p>首先假定我们收集了一批关于西瓜的数据，例如（色泽=青绿；根蒂=蜷缩；敲声=浊响），（色泽=乌黑；根蒂=稍蜷；敲声=沉闷），（色泽=浅白；根蒂=硬挺；敲声=清脆）</p><ul><li>数据集：这组关于西瓜数据的集合即为数据集</li><li>样本（示例）：每条记录是关于每个西瓜的记录，称为一个样本（示例）</li><li>属性（特征）：色泽、根蒂、敲声描述西瓜的性质，称为属性（性质）</li><li>属性值（特征值）：青绿、乌黑等为属性上的取值，称为属性值（特征值）</li><li>属性空间（样本空间、输入空间）：将色泽、根蒂、敲声作为坐标轴，可以形成一个描述西瓜的<strong>三维</strong>空间（d个属性即为d维），称为属性空间（样本空间、输入空间）</li><li>特征向量：每个西瓜在属性空间中有自己的坐标位置，对应一个坐标向量，所以一个样本也称为一个特征向量</li><li>训练（学习）：从数据中学得模型的过程称为<strong>学习或训练</strong>，训练过程中使用的数据称为<strong>训练数据</strong>，使用的每个样本为一个<strong>训练样本</strong>，这些训练样本的集合为<strong>训练集</strong></li><li>学得模型对应了数据中的某一潜在规律，故又称为<strong>假设</strong>，该潜在规律自身，称为<strong>真实或真相</strong>，机器学习的过程就是要令假设接近真相</li></ul><p>在上述概念基础上，如果我们想要学得的模型是一个可判断西瓜是否为好瓜的模型，那么我们应在训练样本（色泽=青绿；根蒂=蜷缩；敲声=浊响）的基础上添加“结果”信息——好瓜，如（（色泽=青绿；根蒂=蜷缩；敲声=浊响），好瓜）</p><ul><li>标记（label）:关于示例结果的信息（好瓜 or 坏瓜）即为标记</li><li>样例：有label的示例即为样例</li><li>标记空间（输出空间）：所有label的集合 根据预测结果的不同，我们可以将学习任务分为两大类：</li><li>分类：若预测的是离散值，例如好瓜、坏瓜，此类学习任务称为分类(classification)，只有两个类别的二分类任务，通常成其中一个类别为“正类”，另一个类别为“反类”</li><li>回归：若预测的是连续值，例如西瓜成熟度0.97、0.35，此类学习任务称为回归(regression)</li><li>测试：学得模型后，用其进行预测的过程称为测试，被预测的样本称为测试样本</li></ul><p>除此之外，即使无label，我们也可以对西瓜进行聚类，将训练集中的西瓜按照其属性分为若干组，每组称为一个“簇”。例如根据色泽，可将西瓜分为深色瓜和浅色瓜等</p><p>根据训练数据是否有label，可以将学习任务大致划分为两大类<strong>监督学习</strong>和<strong>无监督学习</strong></p><ul><li>监督学习：有label，分类和回归是监督学习的代表</li><li>无监督学习：无label，聚类是无监督学习的代表</li></ul><p>机器学习的目标是通过训练数据，使模型也适用于陌生数据，所以模型适用于新样本的能力就称为<strong>泛化能力</strong></p><h4 id="假设空间">假设空间</h4><p>假设空间是由输入空间到输出空间的映射的集合。 假设空间是所有假设的集合，学习过程可以看作是在假设空间中进行搜索的过程，目的是找到与训练集匹配的假设。而现实中，由于训练集有限，所以可能会有多个假设与训练集一致，即存在一个与训练集一致的“假设集合”，称之为“版本空间”。</p><ul><li>具体的例子，比如针对西瓜是否为好瓜这一问题，一个假设就是一个判断规则，比如“如果色泽=青绿，根蒂=蜷缩，那么就是好瓜”或“如果根蒂=硬挺，那么是坏瓜”等，这都是假设，而所有假设构成了假设空间。</li></ul><h4 id="归纳偏好">归纳偏好</h4><p>在面对新样本时，模型采用版本空间中的哪一假设？这事就涉及到了采用算法的归纳偏好，不同的算法有不同的偏好。需要注意，<strong>任何一个机器学习算法都必有其归纳偏好，否则将无法产生确定的学习结果。</strong> 同时对于算法A来说，若其在某些方面比算法B好，那么必然存在一些方面B比A好。这个结论对任何算法均成立，无一例外！所以脱离实际谈论哪个算法更好是毫无意义的。</p><h3 id="模型评估与选择">模型评估与选择</h3><h4 id="经验误差与过拟合">经验误差与过拟合</h4><ul><li>错误率：分类错误的样本数占样本总数的比例</li><li>精度：1-错误率，</li></ul><p>如果在m个样本中有a个样本分类错误，那么错误率 E = a/m，精度 = 1 - E。</p><ul><li>误差：更一般地，把学习器的实际预测输出与样本的真实输出之间的差异称为误差。学习器在训练集上的误差称为<strong>训练误差或经验误差</strong>，在新样本上的误差称为<strong>泛化误差</strong>。</li><li>过拟合：学习能力过强，把训练数据中的非普遍性特征甚至随机噪声都当成了普遍的规律来学习。</li><li>欠拟合：学习能力低下 <img src="/img/过拟合.png" alt="过拟合、欠拟合的直观类比" /></li></ul><h4 id="评估方法">评估方法</h4><p>我们在选择模型时希望选择泛化误差小的模型，因此我们需要一个测试集来测试学习器对于新样本的判别能力，然后使用测试误差作为泛化误差的近似。注意，<strong>训练集和测试集要尽量互斥。</strong> 我们拥有一个数据集D（大小为m），通过以下几种方法对数据集D进行处理，从中产生训练集S和测试集T：</p><ul><li>留出法：直接将数据集D划分为两个<strong>互斥</strong>的集合，其中一个作为训练集S，另一个作为测试集T，一般将约2/3 ~ 4/5的样本用于训练，剩余样本用于测试。且由于单次留出法的估计结果往往不够稳定可靠，使用留出法时一般采用若干次随机划分、重复进行试验评估后取平均值作为留出法的评估结果。</li><li>交叉验证法：将数据集D划分为k个大小相似的互斥子集，然后每次用k-1个子集的并集作为训练集，剩下的那个子集作为测试集，这样就可以得到k组训练、测试集，从而进行k次训练和测试，最终返回这k次测试的均值。 <img src="/img/交叉验证法.png" alt="10折交叉验证法" /></li><li>自助法：从数据集D中<strong>随机有放回</strong>地抽取m次样本，得到一个新的数据集（大小也是m），这个新的数据集可能包含重复的样本。使用这个新的数据集来训练模型，剩下的没有被抽取的样本作为测试集。（根据数学计算，大概有1/3的数据可用于测试）</li></ul><h4 id="性能度量">性能度量</h4><ul><li>均方误差：在<strong>回归</strong>任务中，最常用的指标就是均方误差。 <img src="/img/均方误差.png" alt="公式" /></li></ul><p>接下来介绍分类任务中常用的性能指标</p><ul><li>错误率与精度：错误率是<strong>分类错误</strong>的样本数占样本总数的比例，精度是<strong>分类正确</strong>的样本数占样本总数的比例。</li><li>查准率(precision)、查全率(recall)与F1：查准率也叫做准确率，查全率也叫做召回率。对于二分类问题，根据分类器在测试集上的预测正确与否，将样本划分为四类：</li></ul><ol type="1"><li>TP (True Positive)：真正例，正确预测为正类的样本数量。</li><li>TN (True Negative)：真负例，正确预测为负类的样本数量。</li><li>FP (False Positive)：假正例，错误预测为正类的样本数量。</li><li>FN (False Negative)：假负例，错误预测为负类的样本数量。 查准率P与查全率R定义如下： <img src="/img/PR.png" alt="查准率、查全率" /></li></ol><p>由混淆矩阵易得，查准率指模型预测为正类的样本中，实际为正类的比例，查全率指实际为正类的样本中，被模型正确预测为正类的比例。 一般来说，查全率和查准率是一对矛盾的度量，我们将查准率为纵轴，查全率为横轴作图，就可以得到查准率-查全率曲线，简称“P-R曲线”。如图，A将C完全“包住”，所以A的性能显然优于C，但对于A和B来讲，两者有交叉，无法直观比较两者的优劣，这时会采用平衡点（BEP）来度量，认为A优于B，在平衡点的基础上，进一步优化，得到更常用的<strong>F1度量</strong>。 <img src="/img/P-R曲线.png" alt="P-R曲线" /> <img src="/img/F1度量.png" alt="F1度量公式" /></p><h3 id="线性回归">线性回归</h3><p>假设有n个样本，每个样本有d个属性，例如 <span class="math inline"><em>x</em><sup>(<em>i</em>)</sup> = (<em>x</em><sub>1</sub><sup>(<em>i</em>)</sup>; <em>x</em><sub>2</sub><sup>(<em>i</em>)</sup>; ...; <em>x</em><sub><em>d</em></sub><sup>(<em>i</em>)</sup>)<sup><em>T</em></sup></span>，其中<span class="math inline"><em>x</em><sub><em>j</em></sub><sup>(<em>i</em>)</sup></span>是<span class="math inline"><em>x</em><sup>(<em>i</em>)</sup></span>在第j个属性上的取值，线性模型希望学得预测函数 <span class="math inline"><em>ŷ</em><sup>(<em>i</em>)</sup> = <em>w</em><sub>1</sub><em>x</em><sub>1</sub><sup>(<em>i</em>)</sup> + <em>w</em><sub>2</sub><em>x</em><sub>2</sub><sup>(<em>i</em>)</sup> + ... + <em>w</em><sub><em>d</em></sub><em>x</em><sub><em>d</em></sub><sup>(<em>i</em>)</sup> + <em>b</em></span>（使用<span class="math inline"><em>ŷ</em><sup>(<em>i</em>)</sup></span>表示<span class="math inline"><em>y</em><sup>(<em>i</em>)</sup></span>的预测值），一般写作向量形式 <span class="math inline"><em>ŷ</em><sup>(<em>i</em>)</sup> = <em>w</em><sup><em>T</em></sup><em>x</em><sup>(<em>i</em>)</sup> + <em>b</em></span>，其中<span class="math inline"><em>w</em> = (<em>w</em><sub>1</sub>; <em>w</em><sub>2</sub>; ...; <em>w</em><sub><em>d</em></sub>)<sup><em>T</em></sup></span>，当w和b确定时，线性模型也就确定了。 由于实际情况中得到<span class="math inline"><em>ŷ</em><sup>(<em>i</em>)</sup> = <em>y</em><sup>(<em>i</em>)</sup></span>是很难的，所以我们需要一个度量指标来判断模型对数据的拟合程度。<strong>损失函数</strong>就可以量化目标的实际值与预测值之间的差距。通常我们使用非负数来作为损失，数值越小损失越小拟合程度越好，当完美预测时损失值为0。回归问题中最常用的损失函数为平方误差函数，对于样本i，预测值为 <span class="math inline"><em>ŷ</em><sup>(<em>i</em>)</sup></span>，真实标签值为 <span class="math inline"><em>y</em><sup>(<em>i</em>)</sup></span>，那么平方误差SE就表示为 <img src="/img/QianJianTec1761797236022.svg" alt="损失函数" /></p><p>（<strong>注意：</strong>这里的1/2不会带来本质差别，其存在的意义是之后对损失函数求导后可令系数为1，在形式上简单一些） 上述为度量一个样本，为度量模型在整个数据集上的质量，我们需要计算训练集在n个样本上的损失均值，即均方误差MSE为： <img src="/img/损失均值.png" alt="损失函数" /> 有了度量指标，那么我们的目标就是找到w和b使得训练集上的总损失最小： <img src="/img/损失最小化.png" alt="损失最小化" /></p>接下来为实现损失最小化，首先，我们将偏置b合并到参数w中，令<span class="math inline"><em>b</em> = <em>w</em><sub><em>d</em> + 1</sub></span>,合并方法是在包含所有参数的矩阵中附加一列，如图所示。 首先为参数的初始状态： <!-- ![初始](/img/QianJianTec1761919161520.jpg) --><center><img src="/img/QianJianTec1761919161520.jpg" width="75%" height="75%" /></center>我们将b合并到w中： <!-- ![合并偏置项](/img/QianJianTec1761919084433.jpg) --><center><img src="/img/QianJianTec1761919084433.jpg" width="75%" height="75%" /></center>我们将所有样本合并起来： <!-- ![合并样本](/img/QianJianTec1761918784006.png) --><center><img src="/img/QianJianTec1761918784006.png" width="75%" height="75%" /></center>令<span class="math inline"><em>X</em> = <em>x</em><sup><em>T</em></sup></span>： <!-- ![](/img/QianJianTec1761918118840.jpg) --><center><img src="/img/QianJianTec1761918118840.jpg" width="75%" height="75%" /></center>所以均方误差可转换为下列形式： <!-- ![均方误差](/img/QianJianTec1761922200942.jpg) --><center><img src="/img/QianJianTec1761922200942.jpg" width="40%" height="40%" /></center><p>因此我们的目标就是最小化<span class="math inline">||<em>X</em><em>w</em> − <em>y</em>||<sup>2</sup></span>，我们令MSE关于w的导数为0可以得到解析解，（正规方程，这里不再赘述，感兴趣的可以自行了解），但实际情况不是所有问题都有解析解存在，所以我们采用<strong>梯度下降</strong>的方法。</p><blockquote><p><strong>梯度下降的思想：</strong>开始时随机选择w和b，计算损失函数，然后寻找下一个能让损失函数减少最多的参数组合（当前参数的梯度（即偏导数的向量）的反方向，梯度指明了损失函数最陡峭上升的方向。），持续这么做可以找到一个局部最小值，但这个值不一定为全局最小值，所以采取不同的初始参数组合，可能会得到不同的局部最小值。</p></blockquote>随机梯度下降（SGD）：在一次SGD更新中，随机选取一个训练样本<span class="math inline">(<em>x</em><sup>(<em>i</em>)</sup>, <em>y</em><sup>(<em>i</em>)</sup>)</span>用这个样本计算w的梯度并更新。 <!-- ![SGD](/img/QianJianTec1761928721457.jpg) --><center><img src="/img/QianJianTec1761928721457.jpg" width="40%" height="40%" /></center><p>其中，<span class="math inline"><em>α</em></span>为学习率，决定了每次更新的步长。 <img src="/img/学习率大小的影响.png" alt="学习率大小的影响" /></p>在我们实际应用中，我们会将所有样本都遍历一遍来得到最后的w，这就导致执行速度很慢，因此产生了变体<strong>小批量随机梯度下降</strong>，我们在每次更新时随机抽取一小批样本<span class="math inline">ℬ</span>,它是由固定数量的训练样本组成的。 然后，我们计算小批量的平均损失关于模型参数的导数（也可以称为梯度）。 <!-- ![小批量SGD](/img/QianJianTec1761930267754.jpg) --><center><img src="/img/QianJianTec1761930267754.jpg" width="45%" height="45%" /></center><h3 id="逻辑回归">逻辑回归</h3><p>逻辑回归是一种广泛应用于分类问题的统计学习方法，尽管名字中带有“回归”，但它实际上是一种用于<strong>二分类</strong>问题的算法。 逻辑回归通过使用逻辑函数（也称为 <strong>Sigmoid 函数</strong>）将线性回归的输出映射到 0 和 1 之间，从而预测某个事件发生的概率。 逻辑回归广泛应用于各种分类问题，例如：</p><ul><li>垃圾邮件检测（是/不是）</li><li>肿瘤预测（恶性/良性）</li></ul>sigmoid函数是一个S形函数： <!-- ![sigmoid函数](/img/sigmoid函数.png) --><center><img src="/img/sigmoid函数.png" width="35%" height="35%" /></center><p><br /></p><img src="/img/sigmoid图像.png" alt="sigmoid图像" /> 在逻辑回归中，其输入形式上等同于线性回归的输出，即: <!-- ![逻辑回归公式](/img/QianJianTec1761973408418.png) --><center><img src="/img/QianJianTec1761973408418.png" width="75%" height="75%" /></center><p>在逻辑回归中，我们将正类标记为1，反类标记为0。<span class="math inline"><em>h</em><sub><em>w</em></sub>(<em>x</em>)</span>函数的作用就是给定输入变量，计算出输出等于1的可能性，即<span class="math inline"><em>h</em><sub><em>w</em></sub>(<em>x</em>) = <em>P</em>(<em>y</em> = 1|<em>x</em>; <em>w</em>)</span>。</p><ul><li>例如对一个肿瘤的样本，计算得到 h_w(x) = 0.7，也就是该肿瘤有70%的可能是恶性的。</li></ul><p>一般我们会设置阈值为0.5，当<span class="math inline"><em>h</em><sub><em>w</em></sub>(<em>x</em>) ≥ 0.5</span>时，预测y=1；当<span class="math inline"><em>h</em><sub><em>w</em></sub>(<em>x</em>) &lt; 0.5</span>时，预测y=0。</p><ul><li>例如：假设现在有一个模型，参数w是向量[-3 1 1]。则当 -3+x1+x2 <span class="math inline">≥</span> 0 ，即 x1+x2 <span class="math inline">≥</span> 3 时，模型将预测 y=1 。我们可以绘制直线 x1+x2=3 ，这条线便是我们模型的分界线，将预测为1的区域和预测为0的区域分隔开。 如下图： <img src="/img/例子.png" /></li></ul><p>同线性回归，为找到合适的w，我们需要定义逻辑回归的损失函数，如果我们沿用线性回归中的均方误差为损失函数，将<span class="math inline"><em>h</em><sub><em>w</em></sub>(<em>x</em>)</span>带入其中，会发现我们得到的损失函数是一个非凸函数，如图所示： <img src="/img/非凸函数.png" /> 在这种情况下，损失函数存在许多局部最小值，会影响梯度下降法寻找全局最小值，所以我们不能使用均方误差作为逻辑回归的损失函数，我们重新定义损失函数。</p><p>首先，我要先介绍一下<strong>极大似然估计</strong></p><blockquote><p>极大似然估计是一种在统计学中用于估计概率模型参数的方法。其基本思想是：给定一组数据和一个概率模型，最大似然估计会找到模型参数的值，使得这组数据在该模型下出现的概率（即“似然性”）最大。</p></blockquote><p>已知模型参数<span class="math inline">(<em>θ</em><sub>1</sub>, <em>θ</em><sub>2</sub>, ..., <em>θ</em><sub><em>k</em></sub>)</span>，以及数据集D=<span class="math inline"><em>x</em><sub>1</sub>, <em>x</em><sub>2</sub>, ..., <em>x</em><sub><em>n</em></sub></span>，极大似然估计就是要找到<span class="math inline"><em>θ̂</em></span>使得数据集D出现的概率最大，所以定义似然函数： <img src="/img/似然函数.png" alt="似然函数" /></p><p>然后对似然函数求导，令导数为0得到的<span class="math inline"><em>θ̂</em></span>即为所求，为方便计算，我们一般对等式两侧取对数然后再计算。</p>在我们的逻辑回归中，存在下列关系： <!-- ![](/img/Snipaste_2025-11-01_16-25-15.png) --><center><img src="/img/Snipaste_2025-11-01_16-25-15.png" width="50%" height="50%" /></center>综合起来可写成： <!-- ![](/img/Snipaste_2025-11-01_16-32-57.png) --><center><img src="/img/Snipaste_2025-11-01_16-32-57.png" width="75%" height="75%" /></center><p>由极大似然估计的原理可写出单个样本i的对数似然函数： <img src="/img/Snipaste_2025-11-01_16-51-12.png" /> 最大化对数似然函数就可以求得最符合数据的模型参数w，而我们的损失函数是要最小化，所以我们在对数似然函数前加个负号就可以作为损失函数，同时我们使用整个数据集，得到逻辑回归的损失函数函数： <img src="/img/Snipaste_2025-11-01_16-57-40.png" /></p><p>我们的目标就是最小化J(w)，具体方法也可采用梯度下降，具体推导不再赘述，与线性回归类似。</p><h3 id="决策树">决策树</h3><p>决策树是一种基于树形结构的监督学习算法。它通过从数据中学习并构建一套简单的“如果…那么…”决策规则，来模拟人类的决策过程，从而对实例进行预测。</p><blockquote><p>定义：分类决策树模型是一种描述对实例进行分类的树形结构。决策树由结点和有向边组成。结点有两种类型：内部结点和叶结点。内部结点表示一个特征或属性，叶结点表示一个类。</p></blockquote><p>在这里给出一个判断给出特征的动物是否是猫咪的例子，我们通过动物的耳朵形状、面部形状和是否有胡须这些特征来判断是否是猫咪。 <img src="/img/分辨猫咪.png" alt="是否是猫咪" /></p><p>通过决策树算法我们可能会得到下图这些决策树： <img src="/img/猫咪决策树.png" alt="猫咪决策树" /></p><p>这些决策树都满足给出的表格，但最终只能选择一个作为最终结果，那么我们该如何挑选出最好的那棵决策树？关键就在于我们在每个结点处该选择哪个特征来对数据进行切割。</p><p>在继续学习之前，我们先需要了解熵的概念。<strong>熵是衡量数据纯度的指标。</strong> <img src="/img/熵.png" alt="熵" /></p><p>这是一个具体的例子： <img src="/img/熵例.png" alt="例子" /></p><figure><img src="/img/条件熵.png" alt="条件熵" /><figcaption aria-hidden="true">条件熵</figcaption></figure><p>在了解熵和条件熵后，我们就可以引入<strong>信息增益</strong>的概念。在构建决策树时，初始数据集的熵H(D)代表了其类别的不确定性。当在某个节点处根据一个特征A对数据进行划分后，会产生多个数据子集。计算这些子集的加权平均熵H(D∣A)，即条件熵。初始熵与条件熵的差值H(D)−H(D∣A)被称为信息增益。它量化了通过特征A 、进行划分所获得的信息量，信息增益越大，意味着该特征对类别不确定性的减少越多，该特征对数据集划分所获得的“纯度提升”越大。所以信息增益可以用于决策树划分属性的选择，即<strong>选择信息增益最大</strong>的属性。</p><figure><img src="/img/信息增益算法.png" alt="信息增益算法" /><figcaption aria-hidden="true">信息增益算法</figcaption></figure><p>如下图所示，在选择猫咪判断的根节点时，由于耳朵形状带来的信息增益最大，所以我们在构建决策树时，选择耳朵形状作为根节点。 <img src="/img/信息增益例子.png" alt="信息增益例子" /></p><p>以信息增益作为划分数据集的特征，存在偏向选择取值较多的特征的问题，对于取值很多的特征，它会将数据分割成 n 个小盒子。即使这些划分在本质上没有提供任何信息，但只要 n 足够大，就总会有很大概率创造出许多纯的或近乎纯的小盒子（尤其是当样本量有限时），从而拉低整体的H(D | A)，使得信息增益变大。 在这里举一个极限的例子，假设我们有一个数据集（n个数据），目的是判断一个人是否喜欢玩游戏。其中有一个特征叫 “身份证号”。</p><ul><li>初始熵 H(D)：假设喜欢和不喜欢的人各占一半，熵很高。</li><li>使用“身份证号”进行划分：由于每个人的身份证号都独一无二，这个特征会有n个取值。划分后，每个子集（每个身份证号对应的那个人）都只包含一个样本。</li><li>划分后的熵 H(D | 特征)：每个子集内部只有一个样本，纯度是100%（要么喜欢，要么不喜欢），所以每个子集的熵都为0。这些子集的加权平均熵（条件熵）也为 0。</li><li>信息增益 = H(D) - 0 = H(D)。信息增益达到了理论上的最大值！ 如果根据信息增益来选择特征，“身份证号”这个毫无意义的特征会被选为根节点。</li></ul><p>因此，引入<strong>信息增益比</strong>的概念： <img src="/img/信息增益比.png" alt="信息增益比" /></p><p>使用信息增益比替代信息增益，用于决策树划分属性的选择，即选择信息增益比最大的属性。</p>接下来我们继续介绍<strong>基尼系数</strong><br /><!-- ![基尼系数](/img/QianJianTec1762141787162.jpg) --><center><img src="/img/QianJianTec1762141787162.jpg" width="50%" height="50%" /></center><p><br />如下图所示，基尼系数与熵的定义相比，二者的趋势一致，只是具体计算方式不同，所以我们也可将基尼系数理解为描述体系的混乱程度，基尼系数越大，不确定性越大。</p><!-- ![基尼系数](/img/QianJianTec1762142057963.jpg) --><br /><center><img src="/img/QianJianTec1762142057963.jpg" width="50%" height="50%" /></center><br />类似条件熵，对于基尼系数，同样存在Gini(D, A)来描述经过特征A划分后的混乱程度。<br /><center><img src="/img/QianJianTec1762152398080.jpg" width="50%" height="50%" /></center><p><br /></p><p>使用Gini(D, A)替代信息增益比，用于决策树划分属性的选择，即选择Gini(D, A)小的的属性。这与信息增益和信息增益比不同，<span class="math inline"><em>A</em><sup>*</sup> = <em>a</em><em>r</em><em>g</em> <em>m</em><em>i</em><em>n</em> <em>G</em><em>i</em><em>n</em><em>i</em>(<em>D</em>, <em>A</em>)</span>。</p><p>到此，我们将决策树中常用的三种划分属性（信息增益、信息增益比、基尼系数）介绍完毕。其中使用信息增益作为划分属性的即为ID3算法，使用信息增益比作为划分属性的即为C4.5算法，使用基尼系数作为划分属性的为CART算法。</p><p>接下来我们继续介绍<strong>剪枝</strong>，这是决策树对付“过拟合”的主要手段。</p><blockquote><p>在决策树学习中，为了尽可能正确分类训练样本，不断重复划分节点的过程，如果让它无限制地生长，它会为了拟合训练数据中的每一个细节，甚至包括“噪声”和“特例”，而创造出非常复杂、分支众多的树。所以剪枝的核心思想就是主动去掉树的一些分支（子树或叶子节点），以降低树的复杂度和规模。</p></blockquote><p>剪枝有两种策略：</p><ul><li>预剪枝：预剪枝就是在构造决策树的过程中，先对每个结点在划分前进行估计，若果当前结点的划分不能带来决策树模型泛华性能的提升，则不对当前结点进行划分并且将当前结点标记为叶结点。</li><li>后剪枝：后剪枝就是先把整颗决策树构造完毕，然后自底向上的对非叶结点进行考察，若将该结点对应的子树换为叶结点能够带来泛华性能的提升，则把该子树替换为叶结点。</li></ul><p>刚才我们一直在做分类问题。考虑当特征标签是连续的情况，即此时若我们是在做回归问题，该怎么解决？如下图例子所示： <img src="/img/Snipaste_2025-11-03_18-54-17.png" alt="树回归" /></p><h3 id="集成学习">集成学习</h3><p>单个决策树有一个显著的缺点：它们对训练数据中的微小变化高度敏感。如图所示，仅仅改变一个训练样本的标签（从猫变成狗），就可能导致学习算法构建出一棵结构完全不同的决策树。为了解决单个决策树不稳定的问题，我们可以使用<strong>树集成</strong>的方法。通过结合多个模型的预测结果，使整体性能优于任何单个模型。这一思想的核心是“众人拾柴火焰高”———多个弱模型结合后可以形成一个强模型。 <img src="/img/单棵决策树不稳定.png" alt="单棵决策树的不稳定性" /> <img src="/img/Snipaste_2025-11-11_17-28-15.png" alt="集成学习示意图" /></p><p>常见的集成学习分为三大类：Stacking(堆叠)，Boosting(提升)，Bagging(Bootstrap aggregating，袋装)。</p><h4 id="boosting">Boosting</h4><blockquote><p>Boosting的工作机制：先从初始训练集训练出一个基学习器，再根据基学习器的表现对训练样本分布进行调整，使得先前基学习器做错的训练样本在后续受到更多关注，然后基于调整后的样本分布来训练下一个基学习器；如此重复进行，直至基学习器数目达到事先指定的值T，最后将这T个基学习器进行加权结合。</p></blockquote><p>Boosting算法最著名的就是AdaBoost，接下来我们将介绍该算法。</p><blockquote><p>AdaBoost通过顺序训练多个弱分类器来构建一个强分类器。其核心流程是：</p><ol type="1"><li>首先为所有训练样本赋予相同的初始权重；</li><li>随后，在每一轮迭代中</li></ol><p>    (a)基于当前的样本权重分布训练一个弱分类器</p><p>    (b)计算该弱分类器的加权错误率</p><p>    (c)进而确定其在最终组合中的权重系数</p><p>    (d)之后，根据本轮分类结果更新样本权重——增加被错误分类样本的权重，降低正确分类样本的权重，从而使后续弱分类器更聚焦于之前未能正确处理的样本</p><p>    重复以上过程直至完成预设轮数的训练</p><ol start="3" type="1"><li>最终，将所有弱分类器按其对应权重系数进行加权组合，形成强分类器。</li></ol></blockquote><p>输入：训练数据集<span class="math inline"><em>T</em> = (<em>x</em><sub>1</sub>, <em>y</em><sub>1</sub>), (<em>x</em><sub>2</sub>, <em>y</em><sub>2</sub>), ..., (<em>x</em><sub><em>N</em></sub>, <em>y</em><sub><em>N</em></sub>)</span>，<span class="math inline"><em>x</em><sub><em>i</em></sub></span>为实例，<span class="math inline"><em>y</em><sub><em>i</em></sub> ∈  − 1,  + 1</span>；弱学习算法。 输出：最终分类器G(x)</p><p>(1)初始化训练数据的权值分布<span class="math inline"><em>D</em><sub>1</sub> = (<em>w</em><sub>11</sub>, <em>w</em><sub>12</sub>, ..., <em>w</em><sub>1<em>N</em></sub>)</span>，<span class="math inline"><em>w</em><sub>1<em>i</em></sub> = 1/<em>N</em></span></p><p>(2)循环训练M个弱分类器，对m=1, 2, …, M</p><p>   (a)使用样本权值分布为<span class="math inline"><em>D</em><sub><em>m</em></sub></span>的训练数据集学习，得到基本分类器 <img src="/img/基本分类器.png" alt="基本分类器" /></p><p>   (b)计算<span class="math inline"><em>G</em><sub><em>m</em></sub>(<em>x</em>)</span>在训练数据集上的分类误差率 <img src="/img/分类误差率.png" alt="分类误差率" /></p><p>   (c)计算<span class="math inline"><em>G</em><sub><em>m</em></sub>(<em>x</em>)</span>的系数，这是关于分类错误率<span class="math inline"><em>e</em><sub><em>m</em></sub></span>的单减函数，所以分类错误率低，即更准确的弱分类器在最终分类器中的权重高，符合直觉。 <img src="/img/弱分类器的系数.png" alt="弱分类器的系数" /></p><p>   (d)更新训练集的权值分布，若该样本点被预测正确，那么<span class="math inline"><em>y</em><sub><em>i</em></sub><em>G</em><sub><em>m</em></sub>(<em>x</em>)</span>为1，<span class="math inline"><em>e</em><em>x</em><em>p</em>( − <em>α</em><sub><em>m</em></sub>)</span>小于1，该样本点在下一轮训练时可以弱化，反之，若样本点被预测错误则强化。<span class="math inline"><em>Z</em><sub><em>m</em></sub></span>起归一化的作用。 <img src="/img/训练集的权值分布.png" alt="训练集的权值分布" /></p><p>(3)根据步骤2得到的各分类器即其系数进行组合，构建最终分类器。 <img src="/img/最终分类器.png" alt="最终分类器" /></p><h4 id="bagging">Bagging</h4><p>随机森林是通过构建多棵决策树并集成其结果的机器学习算法，核心是<strong>Bagging + 特征随机性</strong>。</p><p>输入参数：</p><ul><li>训练集 <span class="math inline"><em>D</em> = {(<em>x</em><sub>1</sub>, <em>y</em><sub>1</sub>), (<em>x</em><sub>2</sub>, <em>y</em><sub>2</sub>), ..., (<em>x</em><sub><em>N</em></sub>, <em>y</em><sub><em>N</em></sub>)}</span></li><li>弱学习器（决策树）数量 <span class="math inline"><em>T</em></span></li><li>特征子集大小 <span class="math inline"><em>m</em></span>（通常为总特征数 <span class="math inline"><em>M</em></span> 的平方根或对数）</li></ul><p>对于每棵树 <span class="math inline"><em>t</em> = 1, 2, ..., <em>T</em></span>：</p><p>(1)Bootstrap行采样</p><p>   从原始训练集D中有放回地随机抽取N个样本，形成自助采样集<span class="math inline"><em>D</em><sub><em>t</em></sub></span>，因为每个样本被抽中的概率为 <span class="math inline">1 − (1 − 1/<em>N</em>)<sup><em>N</em></sup> ≈ 63.2%</span>，所以有约36.8%的样本成为<strong>袋外数据（OOB）</strong>，可用于模型验证</p><p>(2)构建决策树 对于树中的每个节点：</p><blockquote><p>   (a)从全部 <span class="math inline"><em>M</em></span> 个特征中随机选择 <span class="math inline"><em>m</em></span> 个特征（<span class="math inline"><em>m</em> ≪ <em>M</em></span>）</p><p>   (b)在选中的 <span class="math inline"><em>m</em></span> 个特征中寻找最优分裂点，然后使用指标（基尼指数、信息增益等）评估分裂质量，最后选择最佳特征和分裂阈值进行节点分裂</p><p>   (c)递归执行上述过程，直到满足停止条件： - 节点中样本数少于最小分裂样本数 - 节点深度达到最大值 - 节点中样本属于同一类别 - 不纯度减少量小于阈值</p><p>   (d)随机森林中的决策树通常<strong>完全生长</strong>，不进行剪枝</p></blockquote><p>在最终预测时，对于分类问题就使用T个决策树对输入进行独立预测，将结果进行投票，少数服从多数得到最终结果。对于回归问题就将每个决策树的结果进行求平均值作为最终输出。</p>]]></content>
    
    
    
  </entry>
  
  
  
  
</search>
